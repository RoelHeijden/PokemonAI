----------------------------------------------------------------------------------------------------------------

explore 2-deep tree search using NE to get scores for each depth

update speed range after instruction (e.g. when checking the case where the bot outspeeds, update speed range in that branch)?

do something with hidden_power_type in battler.from_team_json()

Keep track of potential choice scarf speed_range -- you might know a mon is not max speed scarf before choice scarf is revealed

for bo3 module: update speed_range_check() and others on final turn as well.

find edge case mistakes (like burned pokemon with guts having attack halved), abilities not working in state instructions (Download, synchronize), rocky helmet

fix ability order for turn 1 in instruction generator

extend program to random battles

Implement pressure for pp counting -- see battle_modifier.move()

implement whirlpool trapping knowledge for state simulation (objects.py, side.trapped())

fix damage calculation being calced too often in find_all_state_instructions()

implement trapping knowledge of the opponent for: mean look, jaw lock, block, etc.. (moves that trap untill KO'd or switched)

multi-hit moves KOing a pokemon can wrongfully cause the 'does not have choice band' flag to be set: compares max damage vs damage done by first hit


----------------------------------------------------------------------------------------------------------------



EXPERIMENT 1
    1. finalize setup
        - two simplified teams
            - extremely simplified mirror: 58-42, 52-48, 61, 39
            - simplified mirror:
        - two regular OU teams
            - OU 1 vs OU 2
            - OU 2 vs OU 1
    2. finalize teams
    3. properly document
    4. actually do experiment


INFO MANAGEMENT
    1. Items
        - check/create item deduction functions (e.g. cannot have Life orb, cannot have Leftovers, etc)
        - create has_boosting_item flag (and create boosting item list in constants)
    2. Abilities
        - double check if tracking revealed abilities (e.g. Grassy surge) works well
    3. Speed
        - add terrain healing, intimidate, weather and status damage order to speed_range checker
        - add probabilities to outspeeding/underspeeding
    4. Bulk
        - set hp value between 0-100 (max_hp currently set to 84 EVs hp I believe)
        - create Bayesian model for "bulk" initialized via usage stats
    5. Offense
        - create Bayesian model for "offense" initialized via usage stats
    6. Expand payoff matrix
        - for each possible ability (temporarily set the ability)
        - for each possible item (temporarily set the item)
        - for each bulk/offense/speed range(?)


VALUE NETWORK
    1. Create own version of basic replay analyzer
    2. Mess with Pytorch using those data
    3. research evaluation network structures for non image-like games (e.g. Go board can be seen as pixels)
    4. create first real draft


NASH EQUILIBRIUM
    1. when NE is uniform (doesn't matter which of the N options you pick), pick one with highest average if opp deviates off NE
    2. find the 'best' NE (check if this is being done in Quantecon)
    3. Figure out if Bayesian NE is possible with Quantecon
    4. check NE how u-turn decisions change once evaluation is proper




