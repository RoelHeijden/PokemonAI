----------------------------------------------------------------------------------------------------------------

explore 2-deep tree search using NE to get scores for each depth

update speed range after instruction (e.g. when checking the case where the bot outspeeds, update speed range in that branch)?

Keep track of potential choice scarf speed_range -- you might know a mon is not max speed scarf before choice scarf is revealed

for bo3 module: update speed_range_check() and others on final turn as well.

find edge case mistakes (like burned pokemon with guts having attack halved), abilities not working in state instructions (Download, synchronize), rocky helmet

fix ability order for turn 1 in instruction generator

extend Bot to random battles

Implement pressure for pp counting -- see battle_modifier.move()

fix damage calculation being calced too often in find_all_state_instructions()

implement whirlpool trapping knowledge for state simulation (objects.py, side.trapped())

implement trapping knowledge of the opponent for: mean look, jaw lock, block, etc.. (moves that trap untill KO'd or switched)

multi-hit moves KOing a pokemon can wrongfully cause the 'does not have choice band' flag to be set: compares max damage vs damage done by first hit

detect speed range if faster mon is unable to move (freeze, para, etc)

KO's when the knocked out pokemon was using a -priotiy move wrongfully sets the speed range

----------------------------------------------------------------------------------------------------------------

REGULAR:
    do something with hidden_power_type in battler.from_team_json() and battler from the parser class
    fix zoroark deleting previous pokemon bug

PARSER:
    reserve never empties
    fainted is never set to True

    check switch_or_drag transform handling (it resets the pokemon..)
    check ability cases in start_volatile_status
    test zoroark in granted dataset

    rename user and opponent to p1 and p1
    reduce output size



VALUE NETWORK
    1. Create parser to convert data to game states
    2. Create parser to convert game states to csv
    3. Refresh Pytorch knowledge and make first mini draft
    4. Research evaluation network structures for non image-like games (e.g. Go board can be seen as pixels)
    5. Create first real draft


INFO MANAGEMENT
    1. Items
        - check/create item deduction functions (e.g. cannot have Life orb, cannot have Leftovers, etc)
        - create has_boosting_item flag (and create boosting item list in constants)
    2. Abilities
        - double check if tracking revealed abilities (e.g. Grassy surge) works well
    3. Speed
        - add terrain healing, intimidate, weather and status damage order to speed_range checker
        - add probabilities to outspeeding/underspeeding
    4. Bulk
        - set hp value between 0-100 (max_hp currently set to 84 EVs hp I believe)
        - create Bayesian model for "bulk" initialized via usage stats
    5. Offense
        - create Bayesian model for "offense" initialized via usage stats
    6. Expand payoff matrix
        - for each possible ability (temporarily set the ability)
        - for each possible item (temporarily set the item)
        - for each bulk/offense/speed range(?)


NASH EQUILIBRIUM
    1. when NE is uniform (doesn't matter which of the N options you pick), pick one with highest average in the case the opp deviates from calculated NE
    2. find the 'best' NE (check if this is being done in Quantecon)
    3. Figure out if Bayesian NE is possible via Quantecon
    4. check how NE u-turn decisions change once evaluation is proper




